{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet sCale Attribution Method (WCAM)\n",
    "\n",
    "This notebook is a small tutorial to implement the WCAM on some example images. These images come from [1](https://github.com/fel-thomas/Sobol-Attribution-Method). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import helpers\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "import pywt\n",
    "from spectral_sobol.torch_explainer import WaveletSobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions\n",
    "\n",
    "def rgb_to_wavelet_array(image, wavelet='haar', level=3):\n",
    "    # Convert PIL image to NumPy array\n",
    "    img_array = np.array(image.convert('L'))\n",
    "\n",
    "    # Compute wavelet transform for each channel\n",
    "    c = pywt.wavedec2(img_array, wavelet, level=level)     \n",
    "    # normalize each coefficient array independently for better visibility\n",
    "    c[0] /= np.abs(c[0]).max()\n",
    "    for detail_level in range(level):\n",
    "        c[detail_level + 1] = [d/np.abs(d).max() for d in c[detail_level + 1]]\n",
    "    arr, _ = pywt.coeffs_to_array(c)\n",
    "\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def plot_wcam(ax, image, wcam, levels, vmin = None, vmax = None):\n",
    "    \"\"\"\n",
    "    plts the wcam\n",
    "    \"\"\"\n",
    "    size = image.size[0]\n",
    "    # compute the wavelet transform\n",
    "    wt = rgb_to_wavelet_array(image,level = levels)\n",
    "    \n",
    "    # plots\n",
    "    ax.imshow(wt, cmap = 'gray')\n",
    "    im = ax.imshow(wcam, cmap = \"hot\", alpha = 0.5, vmin = vmin, vmax = vmax)\n",
    "\n",
    "    ax.axis('off')\n",
    "    \n",
    "    helpers.add_lines(size, levels, ax)\n",
    "\n",
    "    #plt.colorbar(im, ax = ax)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set ups\n",
    "device = 'cuda'\n",
    "source = 'assets'\n",
    "batch_size = 128\n",
    "model = torchvision.models.resnet50(pretrained = True).to(device)\n",
    "\n",
    "# parameters for the explainer\n",
    "grid_size = 28\n",
    "nb_design = 8\n",
    "\n",
    "classes = { # dictionnary with the example images and labels\n",
    " 'fox.png': 278,\n",
    " 'snow_fox.png': 279,\n",
    " 'polar_bear.png': 296,\n",
    " 'leopard.png': 288,\n",
    " 'fox1.jpg': 277,\n",
    " 'fox2.jpg': 277,\n",
    " 'sea_turtle.jpg': 33,\n",
    " 'lynx.jpg': 287,\n",
    " 'cat.jpg': 281,\n",
    " 'otter.jpg': 360\n",
    "}\n",
    "\n",
    "# load the images\n",
    "images = [helpers.load_image(source, name) for name in classes.keys()]\n",
    "\n",
    "# convert them as a tensor and define the vector of labels\n",
    "x = torch.stack([torchvision.transforms.ToTensor()(im) for im in images])\n",
    "y = np.array([classes[name] for name in classes.keys()]).astype(np.uint8)\n",
    "\n",
    "# initialize the explainer object\n",
    "wavelet = WaveletSobol(model, grid_size = grid_size, nb_design = nb_design, batch_size = batch_size, opt = {\"approximation\" : False})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've loaded the images and the explainer and set up the data, we can compute the explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = wavelet(x,y) # Depending on your hardware, this can take some time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's it ! We can now visualize our explanations. `explanations` is a list that contains the WCAMs. The spatial WCAMs are stored as an additional attribute to the `WaveletSobol` instance. We can retrieve them by calling `wavelet.spatial_cam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the spatial_wcams : \n",
    "spatial_wcams = wavelet.spatial_cam\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "index = 0\n",
    "\n",
    "ax[0].imshow(images[index])\n",
    "ax[0].axis('off')\n",
    "ax[0].imshow(spatial_wcams[index], cmap = 'jet', alpha = 0.5)\n",
    "\n",
    "plot_wcam(ax[1], images[index], explanations[index], 3)\n",
    "\n",
    "ax[0].set_title('Image and spatial WCAM')\n",
    "ax[1].set_title('WCAM')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations ! Now you know how to use the WCAM and can use it in your own projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acquisition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
