{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivating example\n",
    "\n",
    "Generates the figure 1 of the paper. Takes as input the set of illustration images from Fel et al [1](),[2]() and their corrupted counterparts, corrupted from [3](). \n",
    "\n",
    "Returns the predictions, and the consistency of the predictions. Then plots the predictinos and various explanability methods to show that traditional methods fail to provide insights on why the model failed to accurately predict the label under the given shift.\n",
    "\n",
    "While the failure to provide informative explanation has been studied by earlier works [4](), our focus will be on explaining why a model fails to predict the label under given shifts, leveraging the Wavelet attribution method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from utils import helpers, corruptions\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "from spectral_sobol.torch_explainer import WaveletSobol, SobolAttributionMethod\n",
    "from pytorch_grad_cam import GradCAMPlusPlus\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and the data\n",
    "device = 'cuda:1'\n",
    "source = '../assets'\n",
    "batch_size = 128\n",
    "model = resnet50(pretrained = True).eval().to(device)\n",
    "\n",
    "classes = { # dictionnary with the example images and labels\n",
    " 'fox.png': 278,\n",
    " 'snow_fox.png': 279,\n",
    " 'polar_bear.png': 296,\n",
    " 'leopard.png': 288,\n",
    " 'fox1.jpg': 277,\n",
    " 'fox2.jpg': 277,\n",
    " 'sea_turtle.jpg': 33,\n",
    " 'lynx.jpg': 287,\n",
    " 'cat.jpg': 281,\n",
    " 'otter.jpg': 360\n",
    "}\n",
    "\n",
    "# transforms\n",
    "\n",
    "# misc transforms\n",
    "resize_and_crop = torchvision.transforms.Compose([\n",
    "torchvision.transforms.Resize(256),\n",
    "torchvision.transforms.CenterCrop(224)\n",
    "])\n",
    "\n",
    "\n",
    "# transforms\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocessing = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    "\n",
    "# generate corrupted images\n",
    "# generate and resize the set of corrupted images\n",
    "# in this dictionnary, the 0th image is the source image (uncorrupted)\n",
    "corrupted_images = {\n",
    "    image_name : [resize_and_crop(im) for im in corruptions.generate_corruptions(os.path.join(source, image_name))] for image_name in classes.keys()\n",
    "}\n",
    "\n",
    "# or load the images\n",
    "\n",
    "# corrupted_images = {}\n",
    "# \n",
    "# for image_name in classes.keys():\n",
    "# \n",
    "#     # get to the directory\n",
    "#     destination = '../assets/corrupted/{}'.format(image_name[:-4])\n",
    "#     items = os.listdir(destination)\n",
    "# \n",
    "#     corrupted_images[image_name] = [Image.open(os.path.join(destination, it)).convert('RGB') for it in items]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference \n",
    "\n",
    "Inference on some example images that are corrupted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for image_name in corrupted_images.keys():\n",
    "\n",
    "    batch = corrupted_images[image_name]\n",
    "\n",
    "    x = torch.stack([\n",
    "        preprocessing(im) for im in batch\n",
    "    ])\n",
    "\n",
    "    preds = helpers.evaluate_model_on_samples(x, model, batch_size)\n",
    "\n",
    "    results[image_name] = {\n",
    "        'preds' : preds,\n",
    "        'label' : classes[image_name]\n",
    "    }\n",
    "\n",
    "# display the results\n",
    "# convert the dictionnary as a dataframe\n",
    "corruption_names = [\n",
    "    'source',\n",
    "    'motion-blur',            \n",
    "    'defocus-blur',           \n",
    "    'brightness',             \n",
    "    'spatter',                \n",
    "    'jpeg',                   \n",
    "    'saturate',              \n",
    "    'pixelate',               \n",
    "    'impulse-noise',          \n",
    "    'gaussian-noise',         \n",
    "    'contrast',               \n",
    "    'glass-blur',             \n",
    "    'elastic-transformation', \n",
    "    'shot-noise',             \n",
    "    'gaussian-blur',          \n",
    "]\n",
    "\n",
    "\n",
    "results_df = {\n",
    "    k : [] for k in results.keys()\n",
    "}\n",
    "\n",
    "for k in results_df.keys():\n",
    "    results_df[k].append([results[k]['label']])\n",
    "    results_df[k].append(list(results[k]['preds']))\n",
    "\n",
    "    results_df[k] = list(sum(results_df[k], []))\n",
    "\n",
    "columns = corruption_names\n",
    "columns.insert(0, 'label')\n",
    " \n",
    "df = pd.DataFrame.from_dict(results_df, orient = 'index')\n",
    "df.columns = columns\n",
    "df\n",
    "\n",
    "# load the dataframe\n",
    "df = pd.read_csv('../assets/results_inference.csv', index_col=0)\n",
    "\n",
    "# and re-generate the dictionnary\n",
    "\n",
    "results = {}\n",
    "\n",
    "for item in df.index:\n",
    "    results[item] = {\n",
    "        'preds' : df.loc[item][1:].values,\n",
    "        'label' : classes[item]\n",
    "    }\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataframe\n",
    "df = pd.read_csv('../assets/results_inference.csv', index_col=0)\n",
    "\n",
    "# and re-generate the dictionnary\n",
    "\n",
    "results = {}\n",
    "\n",
    "for item in df.index:\n",
    "    results[item] = {\n",
    "        'preds' : df.loc[item][1:].values,\n",
    "        'label' : classes[item]\n",
    "    }\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate explanations across corruptions\n",
    "\n",
    "We now consider a set of explanations and generate explanations for the different "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# explanations for an image\n",
    "img_name = 'polar_bear.png'\n",
    "\n",
    "# set up the attribution methods\n",
    "# attribution methods\n",
    "sobol = SobolAttributionMethod(model, batch_size = 128)\n",
    "# wavelet \n",
    "wavelet = WaveletSobol(model, grid_size = 28, nb_design = 16, batch_size = 128, opt = {'approximation' : False})\n",
    "# wb expplainers\n",
    "target_layers = [model.layer4[-1]]\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "# cam = GradCAM(model=model.to(device), target_layers=target_layers, use_cuda=True)\n",
    "campp = GradCAMPlusPlus(model=model, target_layers=target_layers, use_cuda=True)\n",
    "\n",
    "# target images\n",
    "#x = torch.stack([\n",
    "#    preprocessing(im) for im in corrupted_images[img_name]\n",
    "#])\n",
    "\n",
    "source_index = 0\n",
    "corruption_index = 1\n",
    "\n",
    "target_images = corrupted_images[img_name]\n",
    "target_images = [target_images[i] for i in [source_index, corruption_index]]\n",
    "\n",
    "x = torch.stack([\n",
    "    preprocessing(im) for im in target_images\n",
    "])\n",
    "\n",
    "# label\n",
    "y = results[img_name]['preds'].astype(int)\n",
    "# label for the wb\n",
    "targets = [ClassifierOutputTarget(c) for c in y]\n",
    "\n",
    "# compute the explanations\n",
    "sobols = sobol(x,y)\n",
    "print('Sobol complete')\n",
    "\n",
    "# wavelet cam \n",
    "# set the option to remove the approximation coefficients from the computation\n",
    "wavelets = wavelet(x,y)\n",
    "print('Wavelet complete')\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# wb\n",
    "# cams = cam(input_tensor=x.to(device), targets=targets, aug_smooth = True)\n",
    "cams_pp = campp(input_tensor=x.to(device), targets=targets, aug_smooth = True)\n",
    "print('WB complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_dir = \"../../data/ImageNet/\"\n",
    "classes_names = json.load(open(os.path.join(imagenet_dir,'classes-imagenet.json')))\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(2,4, figsize = (16, 8))\n",
    "plt.rcParams.update({'font.size': 17})\n",
    "\n",
    "size = 224\n",
    "levels = 3\n",
    "\n",
    "source_index = 0\n",
    "target_index = 1\n",
    "\n",
    "perturbation = 'motion-blur'\n",
    "\n",
    "pred_source = df.loc[img_name][\"source\"]\n",
    "pred_target = df.loc[img_name][perturbation]\n",
    "\n",
    "images = corrupted_images[img_name]\n",
    "\n",
    "# source image and altered image\n",
    "\n",
    "prediction = classes_names[str(pred_source.astype(int))].split(',')[1]\n",
    "prediction_corrupted = classes_names[str(pred_target.astype(int))].split(',')[0]\n",
    "\n",
    "\n",
    "ax[0,0].set_title('Source image \\n Prediction : {}'.format(prediction))\n",
    "ax[0,0].imshow(images[source_index])\n",
    "ax[0,0].axis('off')\n",
    "ax[1,0].set_title('Corrupted image \\n Prediction : {}'.format(prediction_corrupted))\n",
    "ax[1,0].imshow(images[corruption_index])\n",
    "ax[1,0].axis('off')\n",
    "\n",
    "# grad cam\n",
    "ax[0,1].set_title('Grad-CAM ++ \\n Source')\n",
    "ax[0,1].imshow(images[source_index])\n",
    "ax[0,1].imshow(cams_pp[0], cmap = \"jet\", alpha = 0.5)\n",
    "ax[0,1].axis('off')\n",
    "ax[1,1].set_title('Grad-CAM ++ \\n Target')\n",
    "ax[1,1].imshow(images[corruption_index])\n",
    "ax[1,1].imshow(cams_pp[1], cmap = \"jet\", alpha = 0.5)\n",
    "ax[1,1].axis('off')\n",
    "\n",
    "# sobol\n",
    "ax[0,2].set_title('Sobol attribution method \\n Source')\n",
    "ax[0,2].imshow(images[source_index])\n",
    "ax[0,2].imshow(sobols[0], cmap = \"jet\", alpha = 0.5)\n",
    "ax[0,2].axis('off')\n",
    "ax[1,2].set_title('Sobol attribution method \\n Corrupted')\n",
    "ax[1,2].imshow(images[corruption_index])\n",
    "ax[1,2].imshow(sobols[1], cmap = \"jet\", alpha = 0.5)\n",
    "ax[1,2].axis('off')\n",
    "\n",
    "# wavelet\n",
    "# sobol\n",
    "ax[0,3].set_title('Wavelet-CAM (ours) \\n Source')\n",
    "ax[0,3].imshow(wavelets[0], cmap = \"hot\")\n",
    "ax[0,3].axis('off')\n",
    "helpers.add_lines(size, levels, ax[0,3])\n",
    "ax[1,3].set_title('Wavelet-CAM (ours)\\n Corrupted')\n",
    "ax[1,3].imshow(wavelets[1], cmap = \"hot\")\n",
    "helpers.add_lines(size, levels, ax[1,3])\n",
    "ax[1,3].axis('off')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('../figs/motivating_example.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.imshow(wavelets[0], cmap = \"hot\")\n",
    "ax.axis('off')\n",
    "helpers.add_lines(224,3, ax)\n",
    "\n",
    "# plt.savefig('../figs/workflow-diagram/wcam-hot.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acquisition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
