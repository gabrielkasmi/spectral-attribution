{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoom-in and accuracy: how much of the new information do models use?\n",
    "\n",
    "This notebook contains the source code to generate the figures provided in section 4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and imports\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table generation\n",
    "\n",
    "Retrieve the values reported in table 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 10:23:46.410898: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-04 10:23:47.181128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from utils import helpers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'path/to/data/outputs'\n",
    "imagenet_path = 'path/to/imagenet'\n",
    "filename = 'zoom_importance.json'\n",
    "\n",
    "results = json.load(open(os.path.join(data_path, filename)))\n",
    "images = results['images']\n",
    "\n",
    "cases = [k for k in results.keys() if not k == 'images']\n",
    "\n",
    "# for all cases, retrieve the tables and averages\n",
    "\n",
    "aggregate = np.zeros((5, 2 * len(cases)))\n",
    "stds = np.zeros((5, 2 * len(cases)))\n",
    "for i, case in enumerate(cases):\n",
    "    regular = np.mean(results[case]['regular'], axis = 1)\n",
    "    reg_std = np.std(results[case]['regular'], axis = 1)\n",
    "    zoomed = np.mean(results[case]['zoomed'], axis = 1)\n",
    "    zoom_std = np.std(results[case]['zoomed'], axis = 1)\n",
    "    \n",
    "    # add a 0 value for the 4th level of the regular wcam\n",
    "    regular = np.append(regular, 0.)\n",
    "    reg_std = np.append(reg_std, np.nan)\n",
    "\n",
    "    aggregate[:,2*i] = regular\n",
    "    aggregate[:,2*i+1] = zoomed\n",
    "\n",
    "    stds[:,2*i] = reg_std\n",
    "    stds[:,2*i+1] = zoom_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = [k for k in results.keys() if not k == 'images']\n",
    "\n",
    "mean_cases = np.zeros((5, 4))\n",
    "mean_stds = np.zeros((5, 4))\n",
    "\n",
    "\n",
    "for case in ['sin', 'augmix', 'pixmix']:\n",
    "    regular = np.mean(results[case]['regular'], axis = 1)\n",
    "    reg_std = np.std(results[case]['regular'], axis = 1)\n",
    "    zoomed = np.mean(results[case]['zoomed'], axis = 1)\n",
    "    zoom_std = np.std(results[case]['zoomed'], axis = 1)\n",
    "\n",
    "    # add a 0 value for the 4th level of the regular wcam\n",
    "    regular = np.append(regular, 0.)\n",
    "    reg_std = np.append(reg_std, np.nan)\n",
    "\n",
    "    mean_cases[:,0] += regular\n",
    "    mean_stds[:,0] += reg_std\n",
    "\n",
    "    mean_cases[:,1] += zoomed\n",
    "    mean_stds[:,1] += zoom_std\n",
    "\n",
    "\n",
    "for case in ['adv', 'adv_free', 'fast_adv']:\n",
    "    regular = np.mean(results[case]['regular'], axis = 1)\n",
    "    reg_std = np.std(results[case]['regular'], axis = 1)\n",
    "    zoomed = np.mean(results[case]['zoomed'], axis = 1)\n",
    "    zoom_std = np.std(results[case]['zoomed'], axis = 1)\n",
    "\n",
    "    # add a 0 value for the 4th level of the regular wcam\n",
    "    regular = np.append(regular, 0.)\n",
    "    reg_std = np.append(reg_std, np.nan)\n",
    "\n",
    "    mean_cases[:,2] += regular\n",
    "    mean_stds[:,2] += reg_std\n",
    "\n",
    "    mean_cases[:,3] += zoomed\n",
    "    mean_stds[:,3] += zoom_std\n",
    "\n",
    "# average\n",
    "mean_cases /= 3\n",
    "mean_stds /= 3\n",
    "\n",
    "# for all cases, retrieve the tables and averages\n",
    "\n",
    "aggregate = np.zeros((5, 8))\n",
    "stds = np.zeros((5, 8))\n",
    "\n",
    "for case in ['baseline']:\n",
    "    regular = np.mean(results[case]['regular'], axis = 1)\n",
    "    reg_std = np.std(results[case]['regular'], axis = 1)\n",
    "    zoomed = np.mean(results[case]['zoomed'], axis = 1)\n",
    "    zoom_std = np.std(results[case]['zoomed'], axis = 1)\n",
    "    \n",
    "    # add a 0 value for the 4th level of the regular wcam\n",
    "    regular = np.append(regular, 0.)\n",
    "    reg_std = np.append(reg_std, np.nan)\n",
    "\n",
    "    aggregate[:,0] = regular\n",
    "    aggregate[:,1] = zoomed\n",
    "\n",
    "    stds[:,0] = reg_std\n",
    "    stds[:,1] = zoom_std\n",
    "\n",
    "for case in ['vit']:\n",
    "    regular = np.mean(results[case]['regular'], axis = 1)\n",
    "    reg_std = np.std(results[case]['regular'], axis = 1)\n",
    "    zoomed = np.mean(results[case]['zoomed'], axis = 1)\n",
    "    zoom_std = np.std(results[case]['zoomed'], axis = 1)\n",
    "    \n",
    "    # add a 0 value for the 4th level of the regular wcam\n",
    "    regular = np.append(regular, 0.)\n",
    "    reg_std = np.append(reg_std, np.nan)\n",
    "\n",
    "    aggregate[:,-2] = regular\n",
    "    aggregate[:,-1] = zoomed\n",
    "\n",
    "    stds[:,-2] = reg_std\n",
    "    stds[:,-1] = zoom_std\n",
    "\n",
    "aggregate[:,2:4] = mean_cases[:,:2]\n",
    "aggregate[:,4:6] = mean_cases[:,2:]\n",
    "stds[:,2:4] = mean_stds[:,:2]\n",
    "stds[:,4:6] = mean_stds[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table coefficients\n",
      " 0  &0.837\t &0.752\t &0.895\t &0.869\t &0.954\t &0.906\t &0.830\t &0.611\t \n",
      "&(0.064)\t &(0.137)\t &(0.082)\t &(0.101)\t &(0.033)\t &(0.080)\t &(0.075)\t &(0.164)\t \n",
      "\n",
      " 1  &0.130\t &0.190\t &0.077\t &0.095\t &0.039\t &0.080\t &0.137\t &0.295\t \n",
      "&(0.053)\t &(0.107)\t &(0.063)\t &(0.077)\t &(0.029)\t &(0.071)\t &(0.063)\t &(0.132)\t \n",
      "\n",
      " 2  &0.028\t &0.047\t &0.023\t &0.030\t &0.006\t &0.013\t &0.029\t &0.078\t \n",
      "&(0.012)\t &(0.030)\t &(0.024)\t &(0.033)\t &(0.005)\t &(0.011)\t &(0.018)\t &(0.043)\t \n",
      "\n",
      " 3  &0.005\t &0.010\t &0.004\t &0.005\t &0.001\t &0.001\t &0.004\t &0.014\t \n",
      "&(0.002)\t &(0.006)\t &(0.005)\t &(0.005)\t &(0.001)\t &(0.001)\t &(0.002)\t &(0.008)\t \n",
      "\n",
      " 4  &0.000\t &0.001\t &0.000\t &0.001\t &0.000\t &0.000\t &0.000\t &0.002\t \n",
      "&(-) &(0.001)\t &(-) &(0.001)\t &(-) &(0.000)\t &(-) &(0.001)\t \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Table coefficients') \n",
    "\n",
    "for i,(row, row_std) in enumerate(zip(aggregate, stds)):\n",
    "  \n",
    "    values = ' {}  '.format(i)\n",
    "    values_std = ''\n",
    "    for r, r_std in zip(row, row_std):\n",
    "        values = values + '&{:0.3f}\\t '.format(r)\n",
    "        if np.isnan(r_std):\n",
    "            values_std = values_std + '&(-) '\n",
    "        else :\n",
    "            values_std = values_std + '&({:0.3f})\\t '.format(r_std)\n",
    "    values_std = values_std + '\\n'\n",
    "\n",
    "    print(values)\n",
    "    print(values_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['baseline', 'sin', 'adv', 'augmix', 'vit', 'pixmix', 'adv_free', 'fast_adv']\n",
      "Table coefficients\n",
      "Level : 0   0.837\t0.752\t0.890\t0.873\t0.953\t0.903\t0.892\t0.873\t0.830\t0.611\t0.904\t0.863\t0.951\t0.906\t0.959\t0.909\t\n",
      "            (0.064)\t(0.137)\t(0.082)\t(0.102)\t(0.036)\t(0.077)\t(0.088)\t(0.088)\t(0.075)\t(0.164)\t(0.074)\t(0.114)\t(0.033)\t(0.081)\t(0.030)\t(0.081)\t\n",
      "\n",
      "Level : 1   0.130\t0.190\t0.082\t0.091\t0.040\t0.082\t0.080\t0.093\t0.137\t0.295\t0.069\t0.100\t0.042\t0.079\t0.035\t0.078\t\n",
      "            (0.053)\t(0.107)\t(0.063)\t(0.075)\t(0.031)\t(0.069)\t(0.070)\t(0.070)\t(0.063)\t(0.132)\t(0.055)\t(0.086)\t(0.029)\t(0.073)\t(0.027)\t(0.072)\t\n",
      "\n",
      "Level : 2   0.028\t0.047\t0.024\t0.030\t0.006\t0.013\t0.024\t0.029\t0.029\t0.078\t0.022\t0.032\t0.006\t0.013\t0.005\t0.012\t\n",
      "            (0.012)\t(0.030)\t(0.025)\t(0.032)\t(0.006)\t(0.010)\t(0.023)\t(0.030)\t(0.018)\t(0.043)\t(0.023)\t(0.036)\t(0.006)\t(0.011)\t(0.005)\t(0.011)\t\n",
      "\n",
      "Level : 3   0.005\t0.010\t0.004\t0.005\t0.001\t0.001\t0.004\t0.005\t0.004\t0.014\t0.004\t0.005\t0.001\t0.002\t0.001\t0.001\t\n",
      "            (0.002)\t(0.006)\t(0.006)\t(0.004)\t(0.001)\t(0.002)\t(0.005)\t(0.005)\t(0.002)\t(0.008)\t(0.006)\t(0.005)\t(0.001)\t(0.002)\t(0.001)\t(0.001)\t\n",
      "\n",
      "Level : 4   0.000\t0.001\t0.000\t0.001\t0.000\t0.000\t0.000\t0.001\t0.000\t0.002\t0.000\t0.001\t0.000\t0.000\t0.000\t0.000\t\n",
      "            (-)  \t(0.001)\t(-)  \t(0.001)\t(-)  \t(0.000)\t(-)  \t(0.001)\t(-)  \t(0.001)\t(-)  \t(0.001)\t(-)  \t(0.000)\t(-)  \t(0.000)\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cases)\n",
    "print('Table coefficients') \n",
    "\n",
    "for i,(row, row_std) in enumerate(zip(aggregate, stds)):\n",
    "  \n",
    "    values = 'Level : {}   '.format(i)\n",
    "    values_std = '            '\n",
    "    for r, r_std in zip(row, row_std):\n",
    "        values = values + '{:0.3f}\\t'.format(r)\n",
    "        if np.isnan(r_std):\n",
    "            values_std = values_std + '(-)  \\t'\n",
    "        else :\n",
    "            values_std = values_std + '({:0.3f})\\t'.format(r_std)\n",
    "    values_std = values_std + '\\n'\n",
    "\n",
    "    print(values)\n",
    "    print(values_std)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustrations\n",
    "\n",
    "Consider an image, resize it and zoom in and resize it and consider it normal and see how the WCAM changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "from spectral_sobol.torch_explainer import WaveletSobol\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters, images and explanations\n",
    "\n",
    "num_examples = 10 # number of examples to evaluate\n",
    "\n",
    "type = 'baseline' # model type\n",
    "device = 'multi' # device on which the model is sent\n",
    "images_dir = '../../data/ImageNet/'\n",
    "labels = helpers.format_dataframe(images_dir, images[:num_examples])\n",
    "\n",
    "grid_size = 32 # grid size and options\n",
    "opt = {'size' : grid_size}\n",
    "\n",
    "# model and explainer\n",
    "model = helpers.load_model(type, device)\n",
    "wavelet_3 = WaveletSobol(model, grid_size = grid_size, nb_design = 4, batch_size = 256, levels = 3, opt = opt)\n",
    "wavelet_4 = WaveletSobol(model, grid_size = grid_size, nb_design = 4, batch_size = 256, levels = 4, opt = opt)\n",
    "\n",
    "# load the images \n",
    "baseline_transforms = torchvision.transforms.Compose([\n",
    "torchvision.transforms.Resize(256),\n",
    "torchvision.transforms.CenterCrop(224)\n",
    "])\n",
    "\n",
    "zoomed_in = torchvision.transforms.Compose([\n",
    "torchvision.transforms.Resize(512),\n",
    "torchvision.transforms.CenterCrop(224)\n",
    "])\n",
    "\n",
    "normalize = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "# images and their label\n",
    "\n",
    "images_baseline = [\n",
    "    baseline_transforms(Image.open(os.path.join(images_dir,labels.iloc[i]['name'])).convert('RGB')) for i in range(labels.shape[0])\n",
    "]\n",
    "\n",
    "images_zoomed_in = [\n",
    "    zoomed_in(Image.open(os.path.join(images_dir,labels.iloc[i]['name'])).convert('RGB')) for i in range(labels.shape[0])\n",
    "]\n",
    "\n",
    "x_baseline = torch.stack([\n",
    "    normalize(im) for im in images_baseline\n",
    "])\n",
    "\n",
    "x_zoomed_in = torch.stack([\n",
    "    normalize(im) for im in images_zoomed_in\n",
    "])\n",
    "\n",
    "y = labels['label'].values.astype(np.uint8)\n",
    "\n",
    "# compute the explanations\n",
    "expl_baseline = wavelet_3(x_baseline,y)\n",
    "expl_zoomed_in = wavelet_4(x_zoomed_in,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 224\n",
    "\n",
    "# which example to plot\n",
    "index = 7\n",
    "\n",
    "fig, ax = plt.subplots(2,2, figsize = (8,8))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "ax[0,0].set_title('Regular image')\n",
    "\n",
    "ax[0,0].imshow(images_baseline[index])\n",
    "ax[0,0].axis('off')\n",
    "\n",
    "ax[0,1].set_title('Zoomed in image')\n",
    "\n",
    "ax[0,1].imshow(images_zoomed_in[index])\n",
    "ax[0,1].axis('off')\n",
    "\n",
    "ax[1,0].set_title('Regular WCAM')\n",
    "\n",
    "\n",
    "wcam_baseline = cv2.resize(expl_baseline[index], (224,224))\n",
    "ax[1,0].imshow(wcam_baseline, cmap = 'jet')\n",
    "ax[1,0].axis('off')\n",
    "helpers.add_lines(size, 3, ax[1,0])\n",
    "\n",
    "wcam_zoom = cv2.resize(expl_zoomed_in[index], (224,224))\n",
    "ax[1,1].imshow(wcam_zoom, cmap = 'jet')\n",
    "ax[1,1].axis('off')\n",
    "helpers.add_lines(size, 4, ax[1,1])\n",
    "ax[1,1].set_title('Zoomed-in WCAM')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('../figs/wcam_zoom_example.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acquisition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
