{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconstruction\n",
    "\n",
    "Reconstruction of the image with only the most important wavelet coefficients highlighted by the WCAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import helpers\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50\n",
    "import torch\n",
    "import cv2\n",
    "from spectral_sobol.torch_explainer import WaveletSobol\n",
    "import scienceplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders\n",
    "imagenet_dir = \"../../data/ImageNet/\"\n",
    "\n",
    "# device and model\n",
    "device = 'cuda:2'\n",
    "model = resnet50(pretrained = True).to(device)\n",
    "\n",
    "# parameters\n",
    "grid_size = 28\n",
    "batch_size = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up \n",
    "classes = {\n",
    " 'fox.png': 278,\n",
    " 'snow_fox.png': 279,\n",
    " 'polar_bear.png': 296,\n",
    " 'leopard.png': 288,\n",
    " 'fox1.jpg': 277,\n",
    " 'fox2.jpg': 277,\n",
    " 'sea_turtle.jpg': 33,\n",
    " 'lynx.jpg': 287,\n",
    " 'cat.jpg': 281,\n",
    " 'otter.jpg': 360\n",
    "}\n",
    "\n",
    "image_names = list(classes.keys())\n",
    "\n",
    "images = [Image.open('../assets/{}'.format(img_name)) for img_name in image_names]\n",
    "\n",
    "# transforms\n",
    "normalize = torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocessing = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize,\n",
    "])\n",
    " \n",
    "x = torch.stack(\n",
    "    [preprocessing(img) for img in images]\n",
    ")\n",
    "\n",
    "y = np.array([classes[img_name] for img_name in image_names])\n",
    "\n",
    "# compute the explanations\n",
    "# downs\n",
    "wavelet = WaveletSobol(model, grid_size = grid_size, nb_design = 8, batch_size = batch_size, opt = {'size' : grid_size})\n",
    "explanations = wavelet(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the sets of perturbed images\n",
    "altered_images = {\n",
    "    name : helpers.reconstruct_images(image.cpu().permute(1,2,0), cam) for name, image, cam in zip(classes.keys(), x, explanations)\n",
    "}\n",
    "\n",
    "# inference on the altered images\n",
    "altered_inference = {}\n",
    "\n",
    "for image_name in altered_images.keys():\n",
    "\n",
    "    images = altered_images[image_name]\n",
    "\n",
    "    x = torch.stack(\n",
    "        [preprocessing(img) for img in images]  \n",
    "    )\n",
    "    altered_inference[image_name] = {\n",
    "        'preds' : helpers.evaluate_model_on_samples(x, model, batch_size),\n",
    "        'label' : classes[image_name]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some plots of the altered and reconstructed images\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize = (12,12))\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "\n",
    "names = ['fox.png', 'polar_bear.png', 'lynx.jpg']\n",
    "\n",
    "for i,image_name in enumerate(names):\n",
    "\n",
    "    # original image (all coefficients)\n",
    "    ax[i,0].imshow(altered_images[image_name][-1])\n",
    "    ax[i,0].axis('off')\n",
    "    ax[i,1].imshow(altered_images[image_name][0])\n",
    "    ax[i,1].axis('off')\n",
    "    ax[i,2].imshow(altered_images[image_name][-2])\n",
    "    ax[i,2].axis('off')\n",
    "\n",
    "    n_pos = len(altered_images[image_name]) - 2\n",
    "\n",
    "    if i > 0:\n",
    "        ax[i,2].set_title('{} coefficients'.format(n_pos))\n",
    "        ax[i,2].axis('off')\n",
    "\n",
    "ax[0,0].set_title('Original image')\n",
    "ax[0,0].axis('off')\n",
    "ax[0,1].set_title('Higest coefficient')\n",
    "ax[0,1].axis('off')\n",
    "\n",
    "n_pos = len(altered_images[names[0]]) - 1\n",
    "ax[0,2].set_title('Positive coefficients only\\n {} coefficients'.format(n_pos))\n",
    "ax[0,2].axis('off')\n",
    "\n",
    "plt.suptitle('Reconstruction of images with a subset of Wavelet coefficients')\n",
    "plt.savefig('../figs/reconstruction-examples.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some plots of the model' predictions for these images\n",
    "\n",
    "fig, ax = plt.subplots(3,4, figsize = (16,12))\n",
    "\n",
    "size = 224\n",
    "levels = 3\n",
    "\n",
    "names = ['fox.png', 'polar_bear.png', 'lynx.jpg']\n",
    "for i, name in enumerate(names):\n",
    "    \n",
    "    preds, label = altered_inference[name]['preds'], altered_inference[name]['label'] \n",
    "    depth = np.min(np.where(preds == label * np.ones(len(preds)))[0])\n",
    "    class_index = list(classes.keys()).index(name)\n",
    "\n",
    "\n",
    "    # plot the image\n",
    "    ax[i,0].imshow(altered_images[name][-1])\n",
    "    ax[i,0].axis('off')\n",
    "\n",
    "    # plot the minimal correctly predicted image\n",
    "    ax[i,1].imshow(altered_images[name][depth])\n",
    "    ax[i,1].axis('off')\n",
    "\n",
    "    # plot the spatial wcam as overlay\n",
    "    ax[i,2].imshow(altered_images[name][depth])\n",
    "    ax[i,2].imshow(wavelet.spatial_cam[class_index], cmap = 'jet', alpha = 0.5)\n",
    "    ax[i,2].axis('off')\n",
    "\n",
    "    # plot the wcam\n",
    "    class_index = list(classes.keys()).index(name)\n",
    "    wcam = cv2.resize(explanations[class_index], (size, size), interpolation = cv2.INTER_CUBIC)\n",
    "    ax[i,3].imshow(wcam, cmap = 'jet')\n",
    "    ax[i,3].axis('off')\n",
    "    helpers.add_lines(size, levels, ax[i,3])\n",
    "\n",
    "ax[0,0].set_title('Original image')\n",
    "ax[0,1].set_title('Sufficient image')\n",
    "ax[0,2].set_title('Sufficient image \\n and spatial WCAM')\n",
    "ax[0,3].set_title('WCAM')\n",
    "\n",
    "plt.savefig('../figs/reconstruction-sufficient.pdf')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction depth and robustness\n",
    "\n",
    "We define the reconstruction depth as the number of coefficients necessary to reconstruct an image that is accurately predicted by the model. We wonder whether this metric correlates with the robustness of a prediction. We measure the robustness of the prediction as the ratio between images that are accurately predicted over the total number of perturbation. It encompasses two dimensions: the strenth of the corruption and the type of corruption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample images from imagenet\n",
    "np.random.seed(42)\n",
    "n_samples = 100\n",
    "\n",
    "# sample of images\n",
    "source_img_names = np.random.choice(os.listdir(imagenet_dir), n_samples)\n",
    "\n",
    "# labels dataframe\n",
    "labels_true = helpers.format_dataframe(imagenet_dir, source_img_names)\n",
    "\n",
    "# wavelet explainer\n",
    "wavelet = WaveletSobol(model, grid_size = grid_size, nb_design = 8, batch_size = batch_size, opt = {'size' : grid_size})\n",
    "\n",
    "# compute the robustness and reconstruction depth for the set of images\n",
    "robustness, reconstruction_depth = helpers.compute_robustness_and_depth(source_img_names, imagenet_dir, labels_true, wavelet, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib as mpl # troubleshooting\n",
    "# mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "\n",
    "# plots : reconstruction depth v. robustness\n",
    "plt.style.use(['ieee', 'bright'])\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (9,4))\n",
    "\n",
    "no_nans_source = np.where(~np.isnan(reconstruction_depth['source']))[0]\n",
    "no_nans_corrupted = np.where(~np.isnan(reconstruction_depth['corrupted']))[0]\n",
    "\n",
    "ax[0].scatter(robustness, np.array(reconstruction_depth['source']) / 784, label = \"Raw values\")\n",
    "ax[1].scatter(robustness, np.array(reconstruction_depth['corrupted']) / 784, label = \"Raw values\", c = 'red')\n",
    "\n",
    "# regression lines\n",
    "m, b = np.polyfit(np.array(robustness)[no_nans_source], np.array(reconstruction_depth['source'])[no_nans_source]  / 784, 1)\n",
    "ax[0].plot(np.array(robustness), m* np.array(robustness)+b, label = 'Regression line', c = 'black')\n",
    "\n",
    "# regression lines\n",
    "m, b = np.polyfit(np.array(robustness)[no_nans_corrupted], np.array(reconstruction_depth['corrupted'])[no_nans_corrupted] / 784, 1)\n",
    "ax[1].plot(np.array(robustness), m* np.array(robustness)+b, label = 'Regression line', c = 'black')\n",
    "\n",
    "\n",
    "# titles and plots layouts\n",
    "plt.suptitle('Correlation between robustness reconstruction depth (RD)')\n",
    "\n",
    "ax[0].set_xlabel('Robustness to corruptions')\n",
    "ax[1].set_xlabel('Robustness to corruptions')\n",
    "\n",
    "ax[0].set_ylabel('Reconstruction depth')\n",
    "ax[1].set_ylabel('Reconstruction depth')\n",
    "\n",
    "ax[0].set_title('RD with respect to the source image')\n",
    "ax[1].set_title('RD with respect to a corrupted image')\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "\n",
    "# limits\n",
    "eps = 0.05\n",
    "x_min, x_max = np.min(robustness) - eps, np.max(robustness) + eps\n",
    "\n",
    "ax[0].set_xlim(x_min, x_max)\n",
    "ax[1].set_xlim(x_min, x_max)\n",
    "\n",
    "y_min = min(np.nanmin(reconstruction_depth['source']), np.nanmin(reconstruction_depth['corrupted'])) / 784 - eps \n",
    "y_max = max(np.nanmax(reconstruction_depth['source']), np.nanmax(reconstruction_depth['corrupted'])) / 784 + eps \n",
    "\n",
    "ax[0].set_ylim(y_min, y_max)\n",
    "ax[1].set_ylim(y_min, y_max)\n",
    "\n",
    "plt.legend()\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('../figs/reconstruction-robustness-plot.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acquisition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
