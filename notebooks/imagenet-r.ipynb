{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet-R\n",
    "\n",
    "In this notebook, we evaluate the model on samples from ImageNet-A. This dataset contains 200 labels, and for each label a set of \"natural\" adversarial images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import helpers\n",
    "from spectral_sobol.torch_explainer import WaveletSobol\n",
    "import pandas as pd\n",
    "import json\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1'\n",
    "model_name = \"baseline\"\n",
    "imagenet_a_dir = \"../../data/ImageNet-R/\"\n",
    "imagenet_dir = \"../../data/ImageNet/\"\n",
    "\n",
    "# imagenet labels\n",
    "classes = json.load(open(os.path.join(imagenet_dir,'classes-imagenet.json')))\n",
    "\n",
    "\n",
    "# parameters\n",
    "index = 9 # index of the image to evaluate\n",
    "batch_size = 128\n",
    "\n",
    "# load the labels\n",
    "labels = pd.DataFrame.from_dict(json.load(open(os.path.join(imagenet_a_dir, \"labels.json\"))), orient = \"index\").reset_index()\n",
    "labels.columns = [['name', 'label']]\n",
    "labels.head() \n",
    "\n",
    "# clean the folders\n",
    "# for i in range(labels.shape[0]):\n",
    "#     directory = os.path.join(imagenet_a_dir, labels.loc[i][\"name\"])\n",
    "#     names = os.listdir(directory)\n",
    "#     for name in names:\n",
    "#         new_name = name.replace(' ', '')\n",
    "#         os.rename(os.path.join(directory, name), os.path.join(directory, new_name))\n",
    "\n",
    "resize_and_crop = torchvision.transforms.Compose([\n",
    "torchvision.transforms.Resize(256),\n",
    "torchvision.transforms.CenterCrop(224)\n",
    "])\n",
    "\n",
    "directory = os.path.join(imagenet_a_dir, labels.iloc[index]['name'])\n",
    "\n",
    "images = [\n",
    "    resize_and_crop(Image.open(os.path.join(directory, name)).convert('RGB')) for name in os.listdir(directory)\n",
    "]\n",
    "\n",
    "## an imagenet example\n",
    "complete_label = [v for v in classes.values() if labels.loc[index]['label'] in v]\n",
    "in_class = [int(k) for k in classes.keys() if classes[k] in complete_label]\n",
    "in_labels = helpers.format_dataframe(imagenet_dir, filter = None)\n",
    "\n",
    "in_samples = in_labels[in_labels['label'].isin(in_class)]['name'].values\n",
    "\n",
    "in_examples = [\n",
    "    resize_and_crop(Image.open(os.path.join(imagenet_dir, im)).convert('RGB')) for im in in_samples\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the images\n",
    "\n",
    "model = helpers.load_model(model_name, device)\n",
    "\n",
    "# normalisation for inference\n",
    "normalize = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "x = torch.stack([\n",
    "    normalize(im) for im in images\n",
    "])\n",
    "\n",
    "preds = helpers.evaluate_model_on_samples(x,model,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick some images and compute their cams\n",
    "\n",
    "num_samples = 3\n",
    "grid_size = 28\n",
    "nb_design = 4\n",
    "opt = {'approximation' : False}\n",
    "\n",
    "np.random.seed(42)\n",
    "indices = np.random.choice([*range(len(preds))], num_samples)\n",
    "\n",
    "candidates = [images[i] for i in indices]\n",
    "candidates.append(in_examples[0])\n",
    "\n",
    "x_wavelet = torch.stack([\n",
    "    normalize(candidate) for candidate in candidates\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    preds[i] for i in indices\n",
    "])\n",
    "y = np.append(y, int(in_class[0]))\n",
    "\n",
    "wavelet = WaveletSobol(model, grid_size = grid_size, nb_design = nb_design, batch_size = batch_size, opt = opt)\n",
    "explanations = wavelet(x_wavelet, y.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, (num_samples + 1), figsize = (4 * (num_samples + 1), 8))\n",
    "plt.rcParams.update({'font.size': 17})\n",
    "\n",
    "for idx, k in zip(indices, range(num_samples)):\n",
    "\n",
    "    prediction = classes[str(preds[idx].astype(int))].split(',')[0]\n",
    "\n",
    "    ax[0,k + 1].set_title('Pred : {}'.format(prediction))\n",
    "    ax[0,k + 1] .imshow(images[idx])\n",
    "    ax[0,k+ 1 ].imshow(wavelet.spatial_cam[k], alpha = 0.5, cmap = 'jet')\n",
    "    ax[1,k +1 ].set_title('WCAM')\n",
    "    ax[1,k +1 ].imshow(explanations[k], cmap = \"hot\")\n",
    "    helpers.add_lines(224, 3, ax[1,k+1])\n",
    "    \n",
    "    ax[1,k+1].axis('off')\n",
    "    ax[0,k+1].axis('off')\n",
    "\n",
    "ax[0,0].set_title('ImageNet example')\n",
    "ax[0,0].imshow(in_examples[0])\n",
    "ax[0,0].axis('off')\n",
    "\n",
    "ax[1,0].set_title('WCAM')\n",
    "ax[0,0].imshow(wavelet.spatial_cam[-1], cmap = 'jet', alpha = 0.5)\n",
    "ax[1,0].imshow(explanations[-1], cmap = 'hot')\n",
    "helpers.add_lines(224, 3, ax[1,0])\n",
    "ax[1,0].axis('off')\n",
    "\n",
    "plt.suptitle('True class : {}'.format(labels.loc[index]['label']))\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig('../figs/rendition_pred_{}_{}.pdf'.format(model_name, index))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acquisition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
