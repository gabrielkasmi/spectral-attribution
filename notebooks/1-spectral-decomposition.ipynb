{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral profile of model predictions\n",
    "\n",
    "This notebooks displays images computed from the script `spectral_profile.py`. We display WCAMs obtained across various training methods and model backbones to show that the sensitivity to distribution shifts can be explained by a shift in the important regions for the prediction, as highlighted by the WCAM. Existing attribution methods cannot provide such qualitative evidence while robustness analyses have only shown that robust methods are quantitatively less subject to distribution shifts, but did not explicited whether it was because the model behave qualitatively differently. \n",
    "\n",
    "In this work, we provide evidence that the attitude of deep learining models with respect to the scale decomposition of an image is the same across (1) model baselines and (2) training approaches. Differences in robustness between those methods are only quantitative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Libraries \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "\n",
    "root = '../../data/spectral-attribution-outputs/'\n",
    "\n",
    "perturbations = os.listdir(root)\n",
    "\n",
    "# get the name of the images to be plotted for each perturbation\n",
    "images = {\n",
    "    perturbation : os.listdir(os.path.join(root, perturbation)) for perturbation in perturbations\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the baseline case \n",
    "save = None\n",
    "cases = ['baseline']\n",
    "\n",
    "image_name = images['corruptions'][0]\n",
    "\n",
    "directory = os.path.join(os.path.join(root, perturbation), image_name)\n",
    "\n",
    "plot_wcams(directory, cases, save = save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of the adversarial and SIN cases\n",
    "save = None\n",
    "cases = ['adv', 'sin']\n",
    "\n",
    "image_name = images['corruptions'][0]\n",
    "\n",
    "directory = os.path.join(os.path.join(root, perturbation), image_name)\n",
    "\n",
    "plot_wcams(directory, cases, save = save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wcams(directory, cases, opt = None, save = None):\n",
    "    \"\"\"\n",
    "    plots the wcam of the image image_name for the cases \n",
    "    passed as input in the cases inputed in the list\n",
    "\n",
    "    opt is a set of optional parameters if one wants to specify \n",
    "    precise indices \n",
    "    \"\"\"\n",
    "\n",
    "    # open the source and target images\n",
    "    source = Image.open(os.path.join(directory, \"source.png\")).convert('RGB')\n",
    "\n",
    "    if opt is not None and \"index\" in opt.keys():\n",
    "        index = opt['index']\n",
    "\n",
    "    else: # TODO. Consider a random index in the set (altered_1, ... altered_n)\n",
    "        index = 1 \n",
    "\n",
    "    target = Image.open(os.path.join(directory, \"altered_{}.png\".format(index)))\n",
    "\n",
    "    # open the wcams for the cases passed as input\n",
    "\n",
    "    if len(cases) == 1: # only one case to consider, so 2x2 plot\n",
    "\n",
    "        destination = os.path.join(directory, cases[0])\n",
    "\n",
    "        # open the source and target\n",
    "        source_wcam = Image.open(os.path.join(destination, \"wcam_source.png\")).convert('L')\n",
    "        target_wcam = Image.open(os.path.join(destination, \"wcam_target_{}.png\".format(index))).convert('L')\n",
    "\n",
    "        generate_plot([source, target], [source_wcam], [target_wcam], cases, save = save)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        source_wcams = []\n",
    "        target_wcams = []\n",
    "\n",
    "        for case in cases:\n",
    "\n",
    "            destination = os.path.join(directory, case)\n",
    "\n",
    "            source_wcam = Image.open(os.path.join(destination, \"wcam_source.png\")).convert('L')\n",
    "            target_wcam = Image.open(os.path.join(destination, \"wcam_target_{}.png\".format(index))).convert('L')\n",
    "\n",
    "            source_wcams.append(source_wcam)\n",
    "            target_wcams.append(target_wcam)\n",
    "\n",
    "            generate_plot([source, target], source_wcams, target_wcams, cases, save = save)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def generate_plot(images, source_wcams, target_wcams, cases, save = None):\n",
    "    \"\"\"\n",
    "    generates a plot with the images and the wcams\n",
    "    \"\"\"\n",
    "\n",
    "    levels = 3\n",
    "    size = 224\n",
    "\n",
    "    n_cols = 1 + len(source_wcams)\n",
    "\n",
    "    fig, ax = plt.subplots(2, n_cols, figsize = (4 * n_cols, 8))\n",
    "    # add options here\n",
    "\n",
    "    # first column : images\n",
    "    source, target = images\n",
    "    ax[0,0].imshow(source)\n",
    "    ax[0,0].axis('off')\n",
    "    ax[0,0].set_title(\"Source image\")\n",
    "\n",
    "    ax[1,0].imshow(target)\n",
    "    ax[1,0].axis('off')\n",
    "    ax[1,0].set_title(\"Altered image\")\n",
    "\n",
    "    # subsequent columns: wcams\n",
    "    for i, (source_wcam, target_wcam) in enumerate(zip(source_wcams, target_wcams)):\n",
    "\n",
    "        title = '{} base \\n WCAM on the altered image'.format(cases[i])\n",
    "\n",
    "        ax[0, i + 1].imshow(source_wcam, cmap = 'jet')\n",
    "        ax[0, i + 1].axis('off')\n",
    "        ax[0, i + 1].set_title(title)\n",
    "        helpers.add_lines(size, levels, ax[0, i+1])\n",
    "\n",
    "\n",
    "        ax[1, i + 1].imshow(target_wcam, cmap = 'jet')\n",
    "        ax[1, i + 1].axis('off')\n",
    "        ax[1, i + 1].set_title('WCAM on the altered image')\n",
    "        helpers.add_lines(size, levels, ax[0, i+1])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    if save is not None:\n",
    "\n",
    "        plt.savefig(save)\n",
    "    \n",
    "    plt.show()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acquisition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
